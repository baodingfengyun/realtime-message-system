akka {
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  loglevel = "INFO"
  
 actor {
    provider = "akka.cluster.ClusterActorRefProvider"
    
    serializers {
      akka-cluster = "akka.cluster.protobuf.ClusterMessageSerializer"
      kryo="com.romix.akka.serialization.kryo.KryoSerializer"
    }
    serialization-bindings {
      "akka.cluster.ClusterMessage" = akka-cluster
      "com.msg.common.model.OkoMessage" = kryo
    }

    router.type-mapping {
      adaptive-pool = "akka.cluster.routing.AdaptiveLoadBalancingPool"
      adaptive-group = "akka.cluster.routing.AdaptiveLoadBalancingGroup"
    }
    default-dispatcher {
      type = "Dispatcher"
      executor = "thread-pool-executor"
      fork-join-executor {
        parallelism-min = 16
        parallelism-factor = 3.0
        parallelism-max = 64
      }
      thread-pool-executor {
        keep-alive-time = 60s
        core-pool-size-min = 8
        core-pool-size-factor = 3.0
        core-pool-size-max = 64
        max-pool-size-min = 8
        max-pool-size-factor  = 3.0
        max-pool-size-max = 64
        task-queue-size = -1
        task-queue-type = "linked"
        allow-core-timeout = on
      }
      shutdown-timeout = 1s
      throughput = 50
      throughput-deadline-time = 0ms
      attempt-teamwork = on
      mailbox-requirement = ""
    }
        
     kryo  {   
        type = "graph"  
        idstrategy = "incremental"
        serializer-pool-size = 16
        buffer-size = 4096  
        max-buffer-size = -1
        use-manifests = false
        compression = off
        implicit-registration-logging = false 
        kryo-trace = false 
        #kryo-custom-serializer-init = "CustomKryoSerializerInitFQCN"
        mappings {  
            "com.msg.common.model.OkoMessage" = 20,  
            "com.msg.common.model.Sub" = 21,
            "com.msg.common.model.SubOk" = 22,
            "com.msg.common.model.Msg" =  23,
            "com.msg.common.model.ReplySubNum" = 24,
            "com.msg.common.model.Error" = 25,
            "com.msg.common.model.UnSub" = 26,
            "com.msg.common.model.DeadMsg" = 27,
            "com.msg.common.model.Connect" = 28,
            "com.msg.common.model.ListMsg" = 29,
            "com.msg.common.model.Data" = 30,
            "com.msg.common.model.MData" = 31,
            "com.msg.common.model.History" = 32,
            "com.msg.common.model.VisitMsg" = 33
        }
    }
  }
  
   remote {
    log-remote-lifecycle-events = off
    enabled-transports = ["akka.remote.netty.tcp"]
    transport-failure-detector {
      acceptable-heartbeat-pause = 100s
    }
    watch-failure-detector {
     acceptable-heartbeat-pause = 100s
    }
    retry-gate-closed-for = 5 s
    netty.tcp {
      hostname = "127.0.0.1"
      port = 0
      send-buffer-size = 256000b
      receive-buffer-size = 256000b
      maximum-frame-size = 5242880b
      backlog = 4096
      tcp-nodelay = on
      tcp-keepalive = on
      tcp-reuse-addr = off-for-windows
      server-socket-worker-pool {
        pool-size-min = 10
        pool-size-factor = 2.0
        pool-size-max = 30
      }
      client-socket-worker-pool {
        pool-size-min = 10
        pool-size-factor = 2.0
        pool-size-max = 30
      }
    }
    default-remote-dispatcher {
      type = Dispatcher
      executor = "fork-join-executor"
      fork-join-executor {
        parallelism-min = 12
        parallelism-max = 12
      }
    }
  }
  
  cluster {
    gossip-interval = 1s
    gossip-time-to-live = 2s 
    leader-actions-interval = 1s    
    seed-nodes = [
      "akka.tcp://NewEventSystem@127.0.0.1:3551"]
    auto-down-unreachable-after = 10s   
    roles=["BroadEvent"]
  }
  
  contrib.cluster.pub-sub {
      name = distributedPubSubMediator
      gossip-interval = 2s
      removed-time-to-live = 120s
      role = "BroadEvent"
  }
}

websocket{
  wsuri="/websocket"
  port=6061
}

socketio{
  host=""
  port=6062
}
socket{
  host=""
  port=6063
}